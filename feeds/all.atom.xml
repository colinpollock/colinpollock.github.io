<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Colin Pollock</title><link href="http://colinpollock.net/" rel="alternate"></link><link href="http://colinpollock.net/feeds/all.atom.xml" rel="self"></link><id>http://colinpollock.net/</id><updated>2020-03-06T00:00:00-08:00</updated><entry><title>sonorant.io</title><link href="http://colinpollock.net/sonorant-io" rel="alternate"></link><published>2020-03-06T00:00:00-08:00</published><updated>2020-03-06T00:00:00-08:00</updated><author><name>Colin Pollock</name></author><id>tag:colinpollock.net,2020-03-06:/sonorant-io</id><summary type="html">&lt;p&gt;&lt;a href="http://sonorant.io"&gt;sonorant.io&lt;/a&gt; is a web app that lets you iteratively build novel English words by choosing a phoneme (i.e. sound) from a language model's predictions of the next phoneme, one at a time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hello!" src="/images/sonorant-hello.png" title="Hello!"&gt;&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Spelling in English is often ambiguous and misleading, so linguists use the [International Phonetic Alphabet …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://sonorant.io"&gt;sonorant.io&lt;/a&gt; is a web app that lets you iteratively build novel English words by choosing a phoneme (i.e. sound) from a language model's predictions of the next phoneme, one at a time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hello!" src="/images/sonorant-hello.png" title="Hello!"&gt;&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Spelling in English is often ambiguous and misleading, so linguists use the [International Phonetic Alphabet], or IPA, to phonetically represent words. The &lt;a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict"&gt;CMU Pronouncing Dictionary&lt;/a&gt; contains pronunciations in IPA&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; for about 125 thousand words. As an example, the CMU Dict entry for “catfish” is &lt;strong&gt;/ˈkætˌfɪʃ/&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://github.com/colinpollock/sonorant/blob/master/Model%20Training.ipynb"&gt;trained a language model&lt;/a&gt; over these pronunciations and used it to power the UI screenshotted above. Most language models you'll find on the web are modeling how likely full sentences are, but this one models how likely a sequences of sounds is to be an English word.&lt;/p&gt;
&lt;p&gt;Any language model can be used to generate novel sequences of tokens by repeatedly calculating the distribution for what should come next, sampling from the distribution, adding that sampled token to the word, and repeating. It’s common to automate this whole process and have the computer program do the sampling, but for the app I made it’s up to the human to do the sampling.&lt;/p&gt;
&lt;h2&gt;The App&lt;/h2&gt;
&lt;p&gt;When you first see the app you haven’t chosen any phonemes yet so your word is empty and looks like this: &lt;strong&gt;//&lt;/strong&gt;. The chart is a distribution over all phonemes representing which ones the model believes are most likely to come at the beginning of the word. If you click on any phoneme then your word will be updated and the chart will update to represent the distribution for the following phoneme. The updated pronunciation will also be played as audio. You can continue clicking until you click the &lt;strong&gt;&amp;lt;END&gt;&lt;/strong&gt; token, which finishes your word.&lt;/p&gt;
&lt;h2&gt;Playing with the Model&lt;/h2&gt;
&lt;p&gt;The model has learned that the phoneme &lt;strong&gt;/s/&lt;/strong&gt; is very likely at the beginning of a word but that &lt;strong&gt;/ŋ/&lt;/strong&gt; is extremely unlikely. It has also learned that /ˈstr/ is a valid beginning to a word but &lt;strong&gt;/ˈstm/&lt;/strong&gt; is not.&lt;/p&gt;
&lt;p&gt;Here are a few things you can try to do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make the longest word you can.&lt;/li&gt;
&lt;li&gt;Make a word that isn’t actually pronouncable.&lt;/li&gt;
&lt;li&gt;Always select the most likely phoneme to see what the model thinks is the most likely English word. You can also do this after giving a starting point, which would e.g. show you that the most likely word starting with &lt;strong&gt;/ˌtʃ/&lt;/strong&gt; is &lt;strong&gt;/ˌtʃɑːnˈstɛntən/&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;The CMU Dictionary was originally in &lt;a href="https://en.wikipedia.org/wiki/ARPABET"&gt;ARPABET&lt;/a&gt;, but I used &lt;a href="https://github.com/menelik3/cmudict-ipa"&gt;this version&lt;/a&gt; converted to IPA.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="projects"></category><category term="linguistics"></category><category term="language models"></category><category term="pytorch"></category></entry><entry><title>Jeopardy Question Difficulty</title><link href="http://colinpollock.net/jeopardy-question-difficulty" rel="alternate"></link><published>2020-02-14T00:00:00-08:00</published><updated>2020-02-14T00:00:00-08:00</updated><author><name>Colin Pollock</name></author><id>tag:colinpollock.net,2020-02-14:/jeopardy-question-difficulty</id><summary type="html">&lt;p&gt;I made &lt;a href="http://www.trivia-trainer.com/?blog"&gt;Trivia Trainer&lt;/a&gt; to help myself (and other aspiring Jeopardy contestants) get better at Trivia. It works by allowing users to quiz themselves on questions in 53 specific categories (e.g. Literature, Sports, Geography) so that they can track their improvement and identify their weaknesses.&lt;/p&gt;
&lt;p&gt;Unlike on Jeopardy (where …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I made &lt;a href="http://www.trivia-trainer.com/?blog"&gt;Trivia Trainer&lt;/a&gt; to help myself (and other aspiring Jeopardy contestants) get better at Trivia. It works by allowing users to quiz themselves on questions in 53 specific categories (e.g. Literature, Sports, Geography) so that they can track their improvement and identify their weaknesses.&lt;/p&gt;
&lt;p&gt;Unlike on Jeopardy (where usually only a single contestant answers a question), on Trivia Trainer many users answer the same question so the percentage of attempts that are correct nicely captures how easy a question is. Throughout this post I call this &lt;em&gt;percent correct&lt;/em&gt;. And for any given grouping of questions (e.g. Final Jeopardy questions) the percent correct is simply the average percentage correct across all questions in that group.&lt;/p&gt;
&lt;p&gt;In this post I'll explore how Jeopardy question difficulty varies by question type. &lt;strong&gt;Specifically, in this post I'll cover:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How does difficulty increase within a round?&lt;/strong&gt; Is a $400 question twice as difficult as a $200 question?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How does difficulty compare between rounds?&lt;/strong&gt; Is a $400 question in the Jeopardy round actually the same difficulty as a $400 question in the Double Jeopardy round?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How difficult are Daily Doubles relative to other questions in their round?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What about Final jeopardy?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And since Trivia Trainer organizes questions into 53 categories I wanted to see how difficulty varied by category.&lt;/p&gt;
&lt;p&gt;(A quick sidenote: all information here is in aggregate and no individual Trivia Trainer user’s data will ever be shared or made public.)&lt;/p&gt;
&lt;h2&gt;How does Difficulty Increase within the Jeopardy Round?&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Percent correct in the Jeopardy round" src="/images/jeopardy-question-difficulty/first-round.png" title="Percent correct in the Jeopardy round"&gt;&lt;/p&gt;
&lt;p&gt;For every step down the board the correct rate drops by about 7%, from 72% down to 43%. The decrease in percentage correct (i.e. increase in difficulty) makes sense since Jeopardy writers presumably try to increase the difficulty of each question in a round, so when averaging across tens of thousands of questions at each dollar value that trend shows up. Still, I was surprised the change was so regular.&lt;/p&gt;
&lt;h2&gt;How do the Jeopardy and Double Jeopardy Rounds Compare?&lt;/h2&gt;
&lt;p&gt;The plot below contains the same information as the first one but adds in the Double Jeopardy Round.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Percent correct in the Jeopardy and Double Jeopardy rounds" src="/images/jeopardy-question-difficulty/first-and-second-rounds.png" title="Percent correct in the Jeopardy and Double Jeopardy rounds"&gt;&lt;/p&gt;
&lt;p&gt;The Double Jeopardy round starts out more difficult (72% vs 68% for the first question) and is more difficult at each step down the board.&lt;/p&gt;
&lt;p&gt;Both rounds show the same linearly decreasing relationship in percent correct, but Double Jeopardy’s difficulty increases a little more quickly, with percent correct dropping 8.2% at each new depth compared to just 7% for the first round.&lt;/p&gt;
&lt;p&gt;Interestingly the difficulty isn’t dependent on dollar value: the $400 and $800 questions in the Jeopardy round are respectively easier than the $400 and $800 questions in the Double Jeopardy round.&lt;/p&gt;
&lt;h2&gt;How Difficult are Daily Doubles and Final Jeopardy?&lt;/h2&gt;
&lt;p&gt;The plot below shows all the values in the Jeopardy and Double Jeopardy rounds, which we already saw above. It also has the Daily Double in each round and Final Jeopardy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Percent correct in all rounds" src="/images/jeopardy-question-difficulty/three-rounds-and-DD.png" title="Percent correct in all rounds"&gt;&lt;/p&gt;
&lt;p&gt;In the Jeopardy Round the Daily Double is correct 53% of the time, making it comparably difficult to the depth four question ($800) in the Jeopardy Round at 52%. In the Double Jeopardy round the Daily Double is correct 46.5% of the time, putting it closest to the depth three question $1200) at 49% correct.&lt;/p&gt;
&lt;p&gt;Overall this suggests that Jeopardy clue creators are attempting to make Daily Doubles about as difficult as where they show up, which according to &lt;a href="https://www.reddit.com/r/Jeopardy/comments/bs6fyz/locations_of_daily_doubles/"&gt;this interesting Reddit post&lt;/a&gt; is centered on the second to last row in a given category. I suspect that the writers first create the board and after decide where to put the Daily Double, so a Daily Double found in the $1200 square would be easier than one found in the $1600 square. Unfortunately my dataset only indicates a question is a Daily Double but not where on the board it was found so I couldn’t verify this.&lt;/p&gt;
&lt;p&gt;At 39% correct Final Jeopardy falls in between the second hardest (42% for $1600) and hardest (35% for $2000) questions in the Double Jeopardy round. Trivia Trainer users typically only take a few seconds to respond to questions, including the Final Jeopardy question, so I was expecting the percentage correct to be lower here since Final Jeopardy usually requires some time to think a little more creatively.&lt;/p&gt;
&lt;h2&gt;How does Difficulty Vary Across Categories?&lt;/h2&gt;
&lt;p&gt;Here are the percent correct values for the twenty most popular categories in Trivia Trainer. For reference, the global average across all questions in all categories is 53%.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Percent correct by category" src="/images/jeopardy-question-difficulty/by-category.png" title="Percent correct by category"&gt;&lt;/p&gt;
&lt;p&gt;Unsurprisingly (at least for me) the most challenging category is Literature. It’s both very wide and deep, and tends to be very academic. Compare this with something like Wordplay that typically doesn’t require very specific knowledge.&lt;/p&gt;
&lt;p&gt;We can get a little more granular here and dig into Literature, which encompasses many Jeopardy categories like “Short Stories”, “Novels”, etc.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Percent correct by literature category" src="/images/jeopardy-question-difficulty/within-literature.png" title="Percent correct by literature category"&gt;&lt;/p&gt;
&lt;p&gt;Let me know if there are things you think I should look at or if you’ve done a similar analysis!&lt;/p&gt;</content><category term="misc"></category><category term="jeopardy"></category></entry><entry><title>Seinfeld Script Data</title><link href="http://colinpollock.net/seinfeld-script-data" rel="alternate"></link><published>2014-11-02T17:02:00-08:00</published><updated>2020-03-05T23:00:00-08:00</updated><author><name>Colin Pollock</name></author><id>tag:colinpollock.net,2014-11-02:/seinfeld-script-data</id><summary type="html">&lt;p&gt;I grew up watching Seinfeld and for better or worse it formed a large part of my personality. I was too young to watch the early seasons live, but for the later ones I clearly remember the excitement I'd feel at 8:30pm Thursday night when Friends started because that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I grew up watching Seinfeld and for better or worse it formed a large part of my personality. I was too young to watch the early seasons live, but for the later ones I clearly remember the excitement I'd feel at 8:30pm Thursday night when Friends started because that meant it was only half an hour until Seinfeld would come on.&lt;/p&gt;
&lt;p&gt;So when I was experimenting with various natural language processing algorithms I thought it'd be fun to use Seinfeld scripts as a corpus. I packaged up the scripts in a SQLite database, and this post outlines the schema and how you can interact with it.&lt;/p&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;If you want to generate this data yourself check out &lt;a href="http://github.com/colinpollock/seinfeld-scripts"&gt;the code on my github&lt;/a&gt;. If you just want the SQLite DB file please feel free to send me a message on github or email me.&lt;/p&gt;
&lt;h2&gt;Database Schema&lt;/h2&gt;
&lt;p&gt;In this section I'll show the schema for each of the tables and a sample query with results.&lt;/p&gt;
&lt;h3&gt;Episode&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;schema&lt;/span&gt; &lt;span class="n"&gt;episode&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;episode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;PRIMARY&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;season_number&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;episode_number&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;the_date&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;director&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="k"&gt;UNIQUE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;season_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;episode_number&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;EPISODE&lt;/span&gt; &lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;id&lt;/span&gt;  &lt;span class="n"&gt;season_number&lt;/span&gt;   &lt;span class="n"&gt;episode_number&lt;/span&gt;  &lt;span class="n"&gt;title&lt;/span&gt;   &lt;span class="n"&gt;the_date&lt;/span&gt;    &lt;span class="n"&gt;writer&lt;/span&gt;  &lt;span class="n"&gt;director&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;  &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;Beard&lt;/span&gt;   &lt;span class="n"&gt;February&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1995&lt;/span&gt;    &lt;span class="n"&gt;Carol&lt;/span&gt; &lt;span class="n"&gt;Leifer&lt;/span&gt;    &lt;span class="n"&gt;Andy&lt;/span&gt; &lt;span class="n"&gt;Ackerman&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Utterance&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;schema&lt;/span&gt; &lt;span class="n"&gt;utterance&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;utterance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;PRIMARY&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;episode_id&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;utterance_number&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;

    &lt;span class="n"&gt;speaker&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="k"&gt;UNIQUE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;utterance_number&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="k"&gt;FOREIGN&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;REFERENCES&lt;/span&gt; &lt;span class="n"&gt;episode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;UTTERANCE&lt;/span&gt; &lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;id&lt;/span&gt;  &lt;span class="n"&gt;episode_id&lt;/span&gt;  &lt;span class="n"&gt;utterance_number&lt;/span&gt;    &lt;span class="n"&gt;speaker&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="n"&gt;JERRY&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Sentence&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;schema&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;PRIMARY&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;utterance_id&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;sentence_number&lt;/span&gt; &lt;span class="nb"&gt;INTEGER&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nb"&gt;text&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="k"&gt;UNIQUE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;utterance_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence_number&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="k"&gt;FOREIGN&lt;/span&gt; &lt;span class="k"&gt;KEY&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;utterance_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;REFERENCES&lt;/span&gt; &lt;span class="n"&gt;utterance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;SENTENCE&lt;/span&gt; &lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;id&lt;/span&gt;  &lt;span class="n"&gt;utterance_id&lt;/span&gt;    &lt;span class="n"&gt;sentence_number&lt;/span&gt; &lt;span class="nb"&gt;text&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="n"&gt;It&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;too&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Some Simple Statistics&lt;/h2&gt;
&lt;p&gt;There are a lot of potentially interesting things to do with this data, most of which would require further processing. There are some basic but interesting questions that can be answered by simple SQL queries.&lt;/p&gt;
&lt;h3&gt;Which characters speak the most lines?&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;speaker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;utterance&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;speaker&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="k"&gt;count&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;JERRY&lt;/span&gt;       &lt;span class="mi"&gt;14645&lt;/span&gt;
&lt;span class="n"&gt;GEORGE&lt;/span&gt;      &lt;span class="mi"&gt;9613&lt;/span&gt;
&lt;span class="n"&gt;ELAINE&lt;/span&gt;      &lt;span class="mi"&gt;7967&lt;/span&gt;
&lt;span class="n"&gt;KRAMER&lt;/span&gt;      &lt;span class="mi"&gt;6656&lt;/span&gt;
&lt;span class="n"&gt;NEWMAN&lt;/span&gt;      &lt;span class="mi"&gt;625&lt;/span&gt;
&lt;span class="n"&gt;MORTY&lt;/span&gt;       &lt;span class="mi"&gt;502&lt;/span&gt;
&lt;span class="n"&gt;HELEN&lt;/span&gt;       &lt;span class="mi"&gt;470&lt;/span&gt;
&lt;span class="n"&gt;FRANK&lt;/span&gt;       &lt;span class="mi"&gt;429&lt;/span&gt;
&lt;span class="n"&gt;SUSAN&lt;/span&gt;       &lt;span class="mi"&gt;382&lt;/span&gt;
&lt;span class="n"&gt;ESTELLE&lt;/span&gt;     &lt;span class="mi"&gt;273&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That seems about right-- the show is definitely dominated by the four main characters.&lt;/p&gt;
&lt;h3&gt;Which characters have speaking roles in the greatest number of episodes?&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speaker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;DISTINCT&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;episode&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;utterance&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;episode_id&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speaker&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;JERRY&lt;/span&gt;       &lt;span class="mi"&gt;173&lt;/span&gt;
&lt;span class="n"&gt;GEORGE&lt;/span&gt;      &lt;span class="mi"&gt;171&lt;/span&gt;
&lt;span class="n"&gt;KRAMER&lt;/span&gt;      &lt;span class="mi"&gt;170&lt;/span&gt;
&lt;span class="n"&gt;ELAINE&lt;/span&gt;      &lt;span class="mi"&gt;169&lt;/span&gt;
&lt;span class="n"&gt;MAN&lt;/span&gt;         &lt;span class="mi"&gt;53&lt;/span&gt;
&lt;span class="n"&gt;WOMAN&lt;/span&gt;       &lt;span class="mi"&gt;44&lt;/span&gt;
&lt;span class="n"&gt;NEWMAN&lt;/span&gt;      &lt;span class="mi"&gt;43&lt;/span&gt;
&lt;span class="n"&gt;SUSAN&lt;/span&gt;       &lt;span class="mi"&gt;28&lt;/span&gt;
&lt;span class="n"&gt;FRANK&lt;/span&gt;       &lt;span class="mi"&gt;26&lt;/span&gt;
&lt;span class="n"&gt;ESTELLE&lt;/span&gt;     &lt;span class="mi"&gt;24&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The appearances are also dominated by the main cast. Interestingly, some lines are attributed to "MAN" and "WOMAN", which points to some data quality issues. Ideally unnamed characters would have unique names like "MAN WATERING PLANTS".&lt;/p&gt;
&lt;h2&gt;Project Ideas&lt;/h2&gt;
&lt;h3&gt;Script Viewer&lt;/h3&gt;
&lt;p&gt;One of the main reasons I initially got this data together was to learn some front-end skills by developing a better UI for browsing through Seinfeld scripts. I had imagined all kinds of cross-linking between episodes and possibly links off to Wikipedia.&lt;/p&gt;
&lt;h3&gt;Exploration of the Characters&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Do particular characters have catch phrases (maybe high TF-IDF ngrams where TF is within the character's lines and IDF is for all speakers)?&lt;/li&gt;
&lt;li&gt;Are there characters who gain screen time over time?&lt;/li&gt;
&lt;li&gt;How many episodes are heavy on just a few of the main characters (e.g. a Jerry and George episode)?&lt;/li&gt;
&lt;li&gt;How positive, on average, are the various characters? Are there other interesting stylistic characteristics to look at?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Corpus for Exploring NLP Algorithms&lt;/h3&gt;
&lt;p&gt;I like playing with Wikipedia, but it'll be fun to have something a bit smaller and closer to my heart. It'd be fun to play around with language models and to generate sentences for particular characters (e.g. a Kramerish sentence).&lt;/p&gt;</content><category term="misc"></category><category term="seinfeld"></category><category term="data"></category></entry></feed>